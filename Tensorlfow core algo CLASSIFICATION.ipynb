{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Sat Mar 28 18:03:58 2020\n",
    "\n",
    "Tensorflow core algorithms\n",
    "- Classification with tensorflow\n",
    "\n",
    "LINK : https://colab.research.google.com/drive/15Cyy2H7nT40sGR7TBN5wBvgTd57mVKay#forceEdit=true&sandboxMode=true\n",
    "@author: MohammedS2\n",
    "\"\"\"\n",
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import pandas as pd\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nReading/collecting data with KERAS.\\nSepration of TEST, TRAIN set.\\n\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"CLASSIFICATION\"\"\"\n",
    "\"\"\"\n",
    "Reading/collecting data with KERAS.\n",
    "Sepration of TEST, TRAIN set.\n",
    "FEATURE COLUMN\n",
    "TRAINING PROCESS\n",
    "INPUT FUNCTION\n",
    "CREATING THE MODEL\n",
    "TRAINING\n",
    "PREDICTION\n",
    "\n",
    "\"\"\"\n",
    "# from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "# import pandas as pd\n",
    "# import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/download.tensorflow.org/data/iris_training.csv\n",
      "8192/2194 [================================================================================================================] - 0s 4us/step\n",
      "Downloading data from https://storage.googleapis.com/download.tensorflow.org/data/iris_test.csv\n",
      "8192/573 [============================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 0s/step\n"
     ]
    }
   ],
   "source": [
    "#Collecting/ Reading DATA with KERAS\n",
    "train_path = tf.keras.utils.get_file(\"iris_training.csv\", \"https://storage.googleapis.com/download.tensorflow.org/data/iris_training.csv\")\n",
    "test_path = tf.keras.utils.get_file(\"iris_test.csv\", \"https://storage.googleapis.com/download.tensorflow.org/data/iris_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SepalLength</th>\n",
       "      <th>SepalWidth</th>\n",
       "      <th>PetalLength</th>\n",
       "      <th>PetalWidth</th>\n",
       "      <th>Species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.4</td>\n",
       "      <td>2.8</td>\n",
       "      <td>5.6</td>\n",
       "      <td>2.2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>3.3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.9</td>\n",
       "      <td>2.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.7</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.7</td>\n",
       "      <td>3.8</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SepalLength  SepalWidth  PetalLength  PetalWidth  Species\n",
       "0          6.4         2.8          5.6         2.2        2\n",
       "1          5.0         2.3          3.3         1.0        1\n",
       "2          4.9         2.5          4.5         1.7        2\n",
       "3          4.9         3.1          1.5         0.1        0\n",
       "4          5.7         3.8          1.7         0.3        0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#This set doesn't have the column names. so setting column names\n",
    "COL_NAMES = [\"SepalLength\", \"SepalWidth\", \"PetalLength\", \"PetalWidth\", \"Species\"] #To assign column names\n",
    "LABEL_NAMES = [\"Setsoa\", \"Versicolou\", \"Virginica\"] #To assign the target values for 0,1,2 (It's already in numbers\n",
    "train_set = pd.read_csv(train_path, names = COL_NAMES, header = 0)  #Replace the row at HEADER with COL_NAMES\n",
    "test_set = pd.read_csv(test_path, names = COL_NAMES, header = 0)\n",
    "train_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2\n",
       "1    1\n",
       "2    2\n",
       "3    0\n",
       "4    0\n",
       "Name: Species, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y = train_set.pop(\"Species\") \n",
    "test_y = test_set.pop(\"Species\")\n",
    "train_y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(120, 4)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set.shape #120 row and 4 columns/featues(without target value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NumericColumn(key='SepalLength', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), NumericColumn(key='SepalWidth', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), NumericColumn(key='PetalLength', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), NumericColumn(key='PetalWidth', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None)]\n"
     ]
    }
   ],
   "source": [
    "#FEATURE column\n",
    "# create a proper intpu TYPE for the model. checks all column/features available and the values of thiose columns\n",
    "feature_column = []\n",
    "for key in train_set.keys(): \n",
    "    feature_column.append(tf.feature_column.numeric_column(key=key)) #Will hold the unique valeswhich will be given as input to model\n",
    "print(feature_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TRAINING PROCESS  \n",
    "# There are 2 types od models\n",
    "#   - LinerClassifier\n",
    "#   - DNNClassifier (Deep neural network)\n",
    "# No EPOCHs used so no splitting in batches\n",
    "\n",
    "#INPUT FUNCTION - TYPE 2\n",
    "# Creating only input function and using LAMDA to return this function \n",
    "# Not splitting data into EPOCH batches, 1 batch is returned\n",
    "def input_fun(features_df, labels_df, training=True, batch_size=256):\n",
    "    ds = tf.data.Dataset.from_tensor_slices((dict(features_df), labels_df))  #Convert input to tf.DATASET type\n",
    "    \n",
    "    if training:\n",
    "        ds = ds.shuffle(1000).repeat()  #Suffle data but with no repeats of same data rows\n",
    "        \n",
    "    return ds.batch(batch_size)   #Return i bathc\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: C:\\Users\\MOHAMM~2\\AppData\\Local\\Temp\\tmpgt02_mnn\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'C:\\\\Users\\\\MOHAMM~2\\\\AppData\\\\Local\\\\Temp\\\\tmpgt02_mnn', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x00000196291FBDA0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "#CREATING THE MODEL\n",
    "# input layer (4 nodes(from feature col))\n",
    "# hidden 1 layer (30 nodes)\n",
    "# hidden 2 layer (10)\n",
    "#output layer (3 nodes, because 3 target classes)\n",
    "classifier = tf.estimator.DNNClassifier(feature_columns = feature_column, hidden_units=[30, 10], n_classes=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Layer dnn is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Entity <bound method _DNNModelV2.call of <tensorflow_estimator.python.estimator.canned.dnn._DNNModelV2 object at 0x00000196291288D0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method _DNNModelV2.call of <tensorflow_estimator.python.estimator.canned.dnn._DNNModelV2 object at 0x00000196291288D0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\MOHAMM~2\\AppData\\Local\\Temp\\tmpgt02_mnn\\model.ckpt-5000\n",
      "WARNING:tensorflow:From C:\\Users\\mohammeds2\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\training\\saver.py:1069: get_checkpoint_mtimes (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file utilities to get mtimes.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 5000 into C:\\Users\\MOHAMM~2\\AppData\\Local\\Temp\\tmpgt02_mnn\\model.ckpt.\n",
      "INFO:tensorflow:loss = 0.43473163, step = 5000\n",
      "INFO:tensorflow:global_step/sec: 491.391\n",
      "INFO:tensorflow:loss = 0.43360567, step = 5100 (0.202 sec)\n",
      "INFO:tensorflow:global_step/sec: 613.289\n",
      "INFO:tensorflow:loss = 0.4138221, step = 5200 (0.163 sec)\n",
      "INFO:tensorflow:global_step/sec: 673.122\n",
      "INFO:tensorflow:loss = 0.4201141, step = 5300 (0.149 sec)\n",
      "INFO:tensorflow:global_step/sec: 680.014\n",
      "INFO:tensorflow:loss = 0.4323105, step = 5400 (0.147 sec)\n",
      "INFO:tensorflow:global_step/sec: 464.116\n",
      "INFO:tensorflow:loss = 0.4234223, step = 5500 (0.216 sec)\n",
      "INFO:tensorflow:global_step/sec: 547.717\n",
      "INFO:tensorflow:loss = 0.41526163, step = 5600 (0.183 sec)\n",
      "INFO:tensorflow:global_step/sec: 485.936\n",
      "INFO:tensorflow:loss = 0.4046706, step = 5700 (0.206 sec)\n",
      "INFO:tensorflow:global_step/sec: 618.832\n",
      "INFO:tensorflow:loss = 0.40668195, step = 5800 (0.162 sec)\n",
      "INFO:tensorflow:global_step/sec: 535.993\n",
      "INFO:tensorflow:loss = 0.39416474, step = 5900 (0.189 sec)\n",
      "INFO:tensorflow:global_step/sec: 589.71\n",
      "INFO:tensorflow:loss = 0.4138667, step = 6000 (0.169 sec)\n",
      "INFO:tensorflow:global_step/sec: 489.021\n",
      "INFO:tensorflow:loss = 0.39630067, step = 6100 (0.206 sec)\n",
      "INFO:tensorflow:global_step/sec: 227.685\n",
      "INFO:tensorflow:loss = 0.4056024, step = 6200 (0.435 sec)\n",
      "INFO:tensorflow:global_step/sec: 459.88\n",
      "INFO:tensorflow:loss = 0.4044049, step = 6300 (0.218 sec)\n",
      "INFO:tensorflow:global_step/sec: 771.154\n",
      "INFO:tensorflow:loss = 0.38672608, step = 6400 (0.129 sec)\n",
      "INFO:tensorflow:global_step/sec: 742.372\n",
      "INFO:tensorflow:loss = 0.38612592, step = 6500 (0.136 sec)\n",
      "INFO:tensorflow:global_step/sec: 731.058\n",
      "INFO:tensorflow:loss = 0.38121226, step = 6600 (0.137 sec)\n",
      "INFO:tensorflow:global_step/sec: 228.386\n",
      "INFO:tensorflow:loss = 0.37795818, step = 6700 (0.449 sec)\n",
      "INFO:tensorflow:global_step/sec: 268.613\n",
      "INFO:tensorflow:loss = 0.38267446, step = 6800 (0.362 sec)\n",
      "INFO:tensorflow:global_step/sec: 418.104\n",
      "INFO:tensorflow:loss = 0.37577814, step = 6900 (0.238 sec)\n",
      "INFO:tensorflow:global_step/sec: 696.18\n",
      "INFO:tensorflow:loss = 0.37459195, step = 7000 (0.144 sec)\n",
      "INFO:tensorflow:global_step/sec: 433.179\n",
      "INFO:tensorflow:loss = 0.37056655, step = 7100 (0.230 sec)\n",
      "INFO:tensorflow:global_step/sec: 726.444\n",
      "INFO:tensorflow:loss = 0.37296906, step = 7200 (0.139 sec)\n",
      "INFO:tensorflow:global_step/sec: 646.69\n",
      "INFO:tensorflow:loss = 0.3607108, step = 7300 (0.155 sec)\n",
      "INFO:tensorflow:global_step/sec: 696.141\n",
      "INFO:tensorflow:loss = 0.36688536, step = 7400 (0.144 sec)\n",
      "INFO:tensorflow:global_step/sec: 691.503\n",
      "INFO:tensorflow:loss = 0.36894107, step = 7500 (0.145 sec)\n",
      "INFO:tensorflow:global_step/sec: 343.881\n",
      "INFO:tensorflow:loss = 0.34833136, step = 7600 (0.290 sec)\n",
      "INFO:tensorflow:global_step/sec: 465.135\n",
      "INFO:tensorflow:loss = 0.35726097, step = 7700 (0.215 sec)\n",
      "INFO:tensorflow:global_step/sec: 530.523\n",
      "INFO:tensorflow:loss = 0.35939908, step = 7800 (0.188 sec)\n",
      "INFO:tensorflow:global_step/sec: 663.908\n",
      "INFO:tensorflow:loss = 0.35382834, step = 7900 (0.153 sec)\n",
      "INFO:tensorflow:global_step/sec: 466.277\n",
      "INFO:tensorflow:loss = 0.34941775, step = 8000 (0.212 sec)\n",
      "INFO:tensorflow:global_step/sec: 412.476\n",
      "INFO:tensorflow:loss = 0.35081977, step = 8100 (0.245 sec)\n",
      "INFO:tensorflow:global_step/sec: 247.11\n",
      "INFO:tensorflow:loss = 0.34789, step = 8200 (0.403 sec)\n",
      "INFO:tensorflow:global_step/sec: 481.979\n",
      "INFO:tensorflow:loss = 0.3523242, step = 8300 (0.207 sec)\n",
      "INFO:tensorflow:global_step/sec: 705.791\n",
      "INFO:tensorflow:loss = 0.34260195, step = 8400 (0.142 sec)\n",
      "INFO:tensorflow:global_step/sec: 655.396\n",
      "INFO:tensorflow:loss = 0.33671212, step = 8500 (0.153 sec)\n",
      "INFO:tensorflow:global_step/sec: 630.497\n",
      "INFO:tensorflow:loss = 0.3367399, step = 8600 (0.159 sec)\n",
      "INFO:tensorflow:global_step/sec: 600.274\n",
      "INFO:tensorflow:loss = 0.33514956, step = 8700 (0.171 sec)\n",
      "INFO:tensorflow:global_step/sec: 586.282\n",
      "INFO:tensorflow:loss = 0.33434168, step = 8800 (0.166 sec)\n",
      "INFO:tensorflow:global_step/sec: 541.886\n",
      "INFO:tensorflow:loss = 0.33444887, step = 8900 (0.193 sec)\n",
      "INFO:tensorflow:global_step/sec: 203.46\n",
      "INFO:tensorflow:loss = 0.33393854, step = 9000 (0.489 sec)\n",
      "INFO:tensorflow:global_step/sec: 312.653\n",
      "INFO:tensorflow:loss = 0.32095626, step = 9100 (0.316 sec)\n",
      "INFO:tensorflow:global_step/sec: 681.807\n",
      "INFO:tensorflow:loss = 0.3270116, step = 9200 (0.148 sec)\n",
      "INFO:tensorflow:global_step/sec: 586.045\n",
      "INFO:tensorflow:loss = 0.34451726, step = 9300 (0.174 sec)\n",
      "INFO:tensorflow:global_step/sec: 556.95\n",
      "INFO:tensorflow:loss = 0.33112192, step = 9400 (0.177 sec)\n",
      "INFO:tensorflow:global_step/sec: 638.521\n",
      "INFO:tensorflow:loss = 0.32584316, step = 9500 (0.155 sec)\n",
      "INFO:tensorflow:global_step/sec: 671.209\n",
      "INFO:tensorflow:loss = 0.30803847, step = 9600 (0.150 sec)\n",
      "INFO:tensorflow:global_step/sec: 686.636\n",
      "INFO:tensorflow:loss = 0.32372835, step = 9700 (0.146 sec)\n",
      "INFO:tensorflow:global_step/sec: 663.904\n",
      "INFO:tensorflow:loss = 0.31745598, step = 9800 (0.150 sec)\n",
      "INFO:tensorflow:global_step/sec: 663.904\n",
      "INFO:tensorflow:loss = 0.30364573, step = 9900 (0.152 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 10000 into C:\\Users\\MOHAMM~2\\AppData\\Local\\Temp\\tmpgt02_mnn\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.306597.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Layer dnn is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Entity <bound method _DNNModelV2.call of <tensorflow_estimator.python.estimator.canned.dnn._DNNModelV2 object at 0x000001962B58FB70>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Entity <bound method _DNNModelV2.call of <tensorflow_estimator.python.estimator.canned.dnn._DNNModelV2 object at 0x000001962B58FB70>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2020-03-30T23:24:19Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\MOHAMM~2\\AppData\\Local\\Temp\\tmpgt02_mnn\\model.ckpt-10000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2020-03-30-23:24:19\n",
      "INFO:tensorflow:Saving dict for global step 10000: accuracy = 0.93333334, average_loss = 0.3592343, global_step = 10000, loss = 0.3592343\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 10000: C:\\Users\\MOHAMM~2\\AppData\\Local\\Temp\\tmpgt02_mnn\\model.ckpt-10000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.93333334,\n",
       " 'average_loss': 0.3592343,\n",
       " 'loss': 0.3592343,\n",
       " 'global_step': 10000}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#TRAINING\n",
    "train_input_ds = lambda : input_fun(train_set, train_y, training= True)\n",
    "test_inpud_ds = lambda : input_fun(test_set, test_y, training = False)\n",
    "classifier.train(input_fn = train_input_ds, steps= 5000)\n",
    "classifier.evaluate(test_inpud_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Entity <bound method _DNNModelV2.call of <tensorflow_estimator.python.estimator.canned.dnn._DNNModelV2 object at 0x000001962918B518>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method _DNNModelV2.call of <tensorflow_estimator.python.estimator.canned.dnn._DNNModelV2 object at 0x000001962918B518>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\MOHAMM~2\\AppData\\Local\\Temp\\tmpgt02_mnn\\model.ckpt-10000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "Prediction is \"Setosa\" (89.4%)\n",
      "Prediction is \"Versicolor\" (60.7%)\n",
      "Prediction is \"Virginica\" (64.1%)\n"
     ]
    }
   ],
   "source": [
    "#PREDICTION\n",
    "# Here is some example input and expected classes you can try above\n",
    "expected = ['Setosa', 'Versicolor', 'Virginica']\n",
    "predict_x = {\n",
    "    'SepalLength': [5.1, 5.9, 6.9],\n",
    "    'SepalWidth': [3.3, 3.0, 3.1],\n",
    "    'PetalLength': [1.7, 4.2, 5.4],\n",
    "    'PetalWidth': [0.5, 1.5, 2.1],\n",
    "}\n",
    "\n",
    "def input_fn(features, batch_size=256):\n",
    "    # Convert the inputs to a Dataset without labels.\n",
    "    return tf.data.Dataset.from_tensor_slices(dict(features)).batch(batch_size)\n",
    "\n",
    "# features = ['SepalLength', 'SepalWidth', 'PetalLength', 'PetalWidth']\n",
    "# predict = {}\n",
    "# print(\"Please type numeric values as prompted.\")\n",
    "# for feature in features:\n",
    "#   valid = True\n",
    "#   while valid: \n",
    "#     val = input(feature + \": \")\n",
    "#     if not val.isdigit(): valid = False\n",
    "\n",
    "#   predict[feature] = [float(val)]\n",
    "\n",
    "predictions = classifier.predict(input_fn=lambda: input_fn(predict_x))\n",
    "for pred_dict in predictions:\n",
    "    class_id = pred_dict['class_ids'][0]\n",
    "    probability = pred_dict['probabilities'][class_id]\n",
    "\n",
    "    print('Prediction is \"{}\" ({:.1f}%)'.format(\n",
    "        expected[class_id], 100 * probability))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
